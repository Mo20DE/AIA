{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ade700e-1f9a-4268-a809-4f829ce411c8",
   "metadata": {},
   "source": [
    "# Exercise 5: Scene-Dependent Image Segmentation\n",
    "\n",
    "The goal of this homework is to implement a model that seperates foreground and background objects for a specific scene.  \n",
    "We will use the highway scene from the Change Detection dataset:  \n",
    "http://jacarini.dinf.usherbrooke.ca/dataset2014#\n",
    "\n",
    "![input image](highway/input/in001600.jpg \"Title\") ![gt image](highway/groundtruth/gt001600.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b5923-78bb-48e7-8db6-79b35b79b942",
   "metadata": {},
   "source": [
    "## Task 1: Create a custom (Pytorch) dataset\n",
    "\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "You need to create a class that inherets from **from torch.utils.data.Dataset** and implements two methods:\n",
    "- **def \\_\\_len\\_\\_(self)**:  returns the length of the dataset\n",
    "- **def \\_\\_getitem\\_\\_(self, idx)**: given an integer idx returns the data x,y\n",
    "    - x is the image as a float tensor of shape: $(3,H,W)$ \n",
    "    - y is the label image as a mask of shape: $(H,W)$ each pixel should contain the label 0 (background) or 1 (foreground). It is recommended to use the type torch.long\n",
    "    \n",
    "**Tips**:\n",
    "- The first 470 images are not labeled. Just ignore these images. \n",
    "- If possible load all images into memory or even directly to GPU to increase speed.\n",
    "- You can change the resolution to fit your model or your memory\n",
    "- Add data augmentation to increase the data size and model robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce6bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dd0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e120eb7-0349-4bb0-b305-23a0f3bb5e26",
   "metadata": {},
   "source": [
    "## Task 2: Create a custom Segmentation Model\n",
    "\n",
    "- input: a batch of images $(B,3,H,W)$ \n",
    "- output: a batch of pixel-wise class predictions $(B,C,H,W)$, where $C=2$\n",
    "\n",
    "Tips:\n",
    "- It is recommended to use a Fully-Convolutional Neural Network, because it flexible to the input and output resolution.\n",
    "- Use Residual Blocks with convolutional layers.\n",
    "- Base your model on established segmentation models:\n",
    "    - U-Net: https://arxiv.org/abs/1505.04597\n",
    "    - Deeplab: https://arxiv.org/abs/1606.00915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91a8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        batch_norm=True\n",
    "    ):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride, \n",
    "            padding=padding\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) if batch_norm else None\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) if batch_norm else None\n",
    "\n",
    "        # self.downsample = None\n",
    "        # if in_channels != out_channels:\n",
    "        #     self.downsample = nn.Conv2d(\n",
    "        #         in_channels, \n",
    "        #         out_channels, \n",
    "        #         kernel_size=1,\n",
    "        #         padding=0\n",
    "        #     )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # residual = x\n",
    "        # if self.downsample:\n",
    "        #     residual = self.downsample(residual)\n",
    "        #     residual = self.bn1(residual) if self.bn1 else residual\n",
    "\n",
    "        x = self.bn2(self.conv(x)) if self.bn2 else self.conv(x)\n",
    "        x = self.relu(x) # skip-connection applied\n",
    "        return x\n",
    "\n",
    "def createConvSequential(\n",
    "    in_channels,\n",
    "    out_channels,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    padding=1,\n",
    "    batch_norm=True\n",
    "):\n",
    "    sequential = nn.Sequential(\n",
    "        ResidualBlock(in_channels, out_channels, kernel_size, stride, padding, batch_norm),\n",
    "        ResidualBlock(out_channels, out_channels, kernel_size, stride, padding, batch_norm)\n",
    "    )\n",
    "    return sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891fa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # all available channels\n",
    "        self.inp_ch = 3\n",
    "        self.ch1 = 64\n",
    "        self.ch2 = 128\n",
    "        self.ch3 = 256\n",
    "        self.ch4 = 512\n",
    "        self.ch5 = 1024\n",
    "        self.out_ch = 2\n",
    "        # downsampling conv-layers\n",
    "        self.ds1 = createConvSequential(self.inp_ch, self.ch1)\n",
    "        self.ds2 = createConvSequential(self.ch1, self.ch2)\n",
    "        self.ds3 = createConvSequential(self.ch2, self.ch3)\n",
    "        self.ds4 = createConvSequential(self.ch3, self.ch4)\n",
    "        self.ds5 = createConvSequential(self.ch4, self.ch5)\n",
    "        # upsampling conv-layers\n",
    "        self.us1 = createConvSequential(self.ch5, self.ch4)\n",
    "        self.us2 = createConvSequential(self.ch4, self.ch3)\n",
    "        self.us3 = createConvSequential(self.ch3, self.ch2)\n",
    "        self.us4 = createConvSequential(self.ch2, self.ch1)\n",
    "        # modules for chanaging channel sizes\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(self.ch5, self.ch4, kernel_size=2)\n",
    "        self.trans_conv2 = nn.ConvTranspose2d(self.ch4, self.ch3, kernel_size=2)\n",
    "        self.trans_conv3 = nn.ConvTranspose2d(self.ch3, self.ch2, kernel_size=2)\n",
    "        self.trans_conv4 = nn.ConvTranspose2d(self.ch2, self.ch1, kernel_size=2)\n",
    "        self.last_conv = nn.Conv2d(self.ch1, self.out_ch, kernel_size=1)\n",
    "        self.mode = \"bilinear\"\n",
    "    \n",
    "    def add_residual(self, ds_res, x):\n",
    "\n",
    "        target_h, target_w = x.size(2), x.size(3)\n",
    "        input_h, input_w = ds_res.size(2), ds_res.size(3)\n",
    "\n",
    "        x_start = (input_h - target_h) // 2\n",
    "        y_start = (input_w - target_w) // 2\n",
    "        # print(dims1, dims2, (dims1 - dims2), ((dims1 - dims2) / 2).long())\n",
    "        #tensor([22, 32]) tensor([ 8, 13]) tensor([14, 19]) tensor([7, 9])\n",
    "        # even - uneven = uneven  32, 13: 32-13=19, 19/2=9, 32-(2*9)=14     # goal is 13\n",
    "        # uneven - even = uneven 33, 12: 33-12=21, 21/2=11, 32-(2*11)=10     # goal is 13\n",
    "\n",
    "        if x_start < 0 or y_start < 0:\n",
    "            ds_res = F.interpolate(ds_res, size=(target_h, target_w), mode=self.mode)\n",
    "            cropped = ds_res\n",
    "        else:\n",
    "            cropped = ds_res[:, :, x_start :  x_start + target_h, y_start : y_start + target_w]\n",
    "        \n",
    "        x = torch.concatenate((cropped, x), dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # downsampling path\n",
    "        ds_res1 = self.ds1(x)\n",
    "        x = self.max_pool(ds_res1)\n",
    "\n",
    "        ds_res2 = self.ds2(x)\n",
    "        x = self.max_pool(ds_res2)\n",
    "\n",
    "        ds_res3 = self.ds3(x)\n",
    "        x = self.max_pool(ds_res3)\n",
    "\n",
    "        ds_res4 = self.ds4(x)\n",
    "        x = self.max_pool(ds_res4)\n",
    "\n",
    "        x = self.ds5(x)\n",
    "\n",
    "        # upsampling path, crop and concatenate\n",
    "        x = F.interpolate(x, scale_factor=2, mode=self.mode)\n",
    "        x = self.trans_conv1(x)\n",
    "        x = self.add_residual(ds_res4, x)\n",
    "        x = self.us1(x)\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2, mode=self.mode)\n",
    "        x = self.trans_conv2(x)\n",
    "        x = self.add_residual(ds_res3, x)\n",
    "        x = self.us2(x)\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2, mode=self.mode)\n",
    "        x = self.trans_conv3(x)\n",
    "        x = self.add_residual(ds_res2, x)\n",
    "        x = self.us3(x)\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2, mode=self.mode)\n",
    "        x = self.trans_conv4(x)\n",
    "        x = self.add_residual(ds_res1, x)\n",
    "        x = self.us4(x)\n",
    "        \n",
    "        x = self.last_conv(x) # differentiate between fore- and background by creating 2 masks\n",
    "        x = F.interpolate(x, size=(240, 320), mode=\"bilinear\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85364b0-7010-4710-9373-94a89db8d7c5",
   "metadata": {},
   "source": [
    "## Task 3: Create a training loop\n",
    "- split data into training and test data, e.g. 80% training data and 20% test data using your custom dataset.\n",
    "- Create a Dataloader for your custom datasets \n",
    "- Define a training loop for a single epoch:\n",
    "    - forward pass\n",
    "    - Loss function, e.g. cross entropy\n",
    "    - optimizer \n",
    "    - backward pass\n",
    "    - logging\n",
    "- Define validation loop:\n",
    "    - forward pass\n",
    "    - extract binary labels, e.g. threshold or argmax for each pixel.\n",
    "    - compute evaluation metrics: Accuracy, Precision, Recall and Intersection over Union for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72fb59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    device,\n",
    "    train_loader,\n",
    "    validation_loader,\n",
    "    train_func,\n",
    "    validation_func,\n",
    "    lr=0.001, \n",
    "    momentum=0,\n",
    "    step_size=5, \n",
    "    gamma=0.1, \n",
    "    epochs=10,\n",
    "    **additional_params\n",
    "):\n",
    "    train_params = additional_params.pop(\"train_params\", {})\n",
    "    test_params = additional_params.pop(\"validation_params\", {})\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_func(model, device, train_loader, optimizer, epoch, **train_params)\n",
    "        validation_func(model, device, validation_loader, epoch, **test_params)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2281fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_segmentation_model(\n",
    "    model, \n",
    "    device, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    epoch\n",
    "):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # target label - ground truth\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # output = torch.argmax(output, dim=1).float() # pick the according class-labels by picking highest values\n",
    "        # img = plt.imshow(output.squeeze(0), cmap=\"gray\")\n",
    "        # print(output.shape, target.shape)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            data_processed_so_far = batch_idx * len(data)\n",
    "            total_data = len(train_loader.dataset)\n",
    "            progress = 100. * batch_idx / len(train_loader)\n",
    "            print(\"Train Epoch {}: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, data_processed_so_far, total_data, progress, loss.item()\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "\n",
    "def validate_segmentation_model(\n",
    "    model, \n",
    "    device, \n",
    "    test_loader, \n",
    "    epoch\n",
    "):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    total_data = len(test_loader.dataset)\n",
    "    test_loss /= total_data\n",
    "    progress = 100. * correct / total_data\n",
    "    print(\"Test Set (Epoch {}): Average Loss: {:.4f}\\tAccuracy: {}/{} ({:.0f}%){}\".format(\n",
    "        epoch, test_loss, correct, total_data, progress, 80 * \" \"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a67c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "img_paths = sorted(glob.glob(\"highway/input/*.jpg\"))\n",
    "imgs = [read_image(img_path).float() for img_path in img_paths]\n",
    "img_label_paths = sorted(glob.glob(\"highway/groundtruth/*.png\"))\n",
    "img_labels = [read_image(img_label_path).bool().int().long().squeeze() for img_label_path in img_label_paths]\n",
    "\n",
    "# split dataset (80/20)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(imgs, img_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e18a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: [0/984 (0%)]\tLoss: 0.663905\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m unet_model = UNet().to(device)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43munet_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_segmentation_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_segmentation_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmomentum\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, device, train_loader, validation_loader, train_func, validation_func, lr, momentum, step_size, gamma, epochs, **additional_params)\u001b[39m\n\u001b[32m     18\u001b[39m scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     validation_func(model, device, validation_loader, epoch, **test_params)\n\u001b[32m     22\u001b[39m     scheduler.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_segmentation_model\u001b[39m\u001b[34m(model, device, train_loader, optimizer, epoch)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# output = torch.argmax(output, dim=1).float() # pick the according class-labels by picking highest values\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# img = plt.imshow(output.squeeze(0), cmap=\"gray\")\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# print(output.shape, target.shape)\u001b[39;00m\n\u001b[32m     16\u001b[39m loss = F.cross_entropy(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_idx % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 8\n",
    "momentum = 0.99\n",
    "\n",
    "# create training and validation loaders\n",
    "train_dataset = ChangeDetectionDataset(X_train, y_train)\n",
    "validation_dataset = ChangeDetectionDataset(X_validation, y_validation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "\n",
    "# run training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet_model = UNet().to(device)\n",
    "train_model(\n",
    "    unet_model,\n",
    "    device,\n",
    "    train_loader,\n",
    "    validation_loader,\n",
    "    train_segmentation_model,\n",
    "    validate_segmentation_model,\n",
    "    momentum=momentum\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e603ff-a32e-4d90-84d9-eba8570d6e63",
   "metadata": {},
   "source": [
    "## Task 4: Small Report of your model and training\n",
    "- visualize training and test error over each epoch\n",
    "- report the evaluation metrics of the final model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
